{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aW9NVz2Np6Ei"
   },
   "source": [
    "### Review part [20 Min]:\n",
    "\n",
    "1. See Sep20 TUT and Sep23 LEC\n",
    "\n",
    "    1. What is a histogram and what does it describe about the data?\n",
    "\n",
    "    2. What general conclusions regarding the use of barplots and histograms regarding comparisions sample size considerations can we make from the following examples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objects as go\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load / reset df\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/2e9bd5a67e09b14d01f616b00f7f7e0931515d24/data/2020/2020-07-07/coffee_ratings.csv\")\n",
    "df = df[df['total_cup_points']>65]\n",
    "df = df[~df['country_of_origin'].isna()]\n",
    "df = df.rename(columns={'country_of_origin': 'origin', 'total_cup_points': 'points'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix titles\n",
    "df.origin = df.origin.str.replace(\" (\", \"<br>(\")\n",
    "df.origin = df.origin.str.replace(\", \", \",<br>\")\n",
    "\n",
    "fig = px.histogram(df, x='points', facet_col='origin', \n",
    "             facet_col_wrap=6, height=1000, facet_row_spacing=0.05)\n",
    "\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.replace(\"origin=\", \"\"))) # fix titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.origin = df.origin.str.replace(\"<br>\", \" \") # fix labels\n",
    "\n",
    "fig = px.box(df, x='points', y=\"origin\", height=750)\n",
    "\n",
    "# order plot to be more visually interpretable\n",
    "fig.update_yaxes(categoryorder='array', \n",
    "                 categoryarray=df.groupby(\"origin\")['points'].mean().sort_values().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in missing sample sizes\n",
    "keys = df.origin.value_counts().index.values\n",
    "vals = df.origin.value_counts().index.values + \" (n=\"+df.origin.value_counts().values.astype(str)+\")\"\n",
    "df.origin = df.origin.map({k:v for k,v in zip(keys,vals)})\n",
    "\n",
    "fig = px.box(df, x='points', y=\"origin\", height=750)\n",
    "fig.update_yaxes(categoryorder='array', \n",
    "                 categoryarray=df.groupby(\"origin\")['points'].mean().sort_values().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1y4dx7iqfFt"
   },
   "source": [
    "### Demo [40 minutes]\n",
    "\n",
    "#### Estimating Averages [20/40 minutes]\n",
    "\n",
    "1. For which countries above do you think we can most accurately estimate the average \"points\" score of cups of coffee from a given country? \n",
    "2. How does the variability of means of simulated samples change as a function of sample size?\n",
    "3. Does this seem to change if using (symmetric) `normal`, (skewed) `gamma`, or (other empirical shapes) when using **bootstrapped samples**? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix titles\n",
    "df.origin = df.origin.str.replace(\" (\", \"<br>(\")\n",
    "df.origin = df.origin.str.replace(\", \", \",<br>\")\n",
    "\n",
    "fig = px.histogram(df, x='points', facet_col='origin', \n",
    "                   facet_col_wrap=6, height=1000, facet_row_spacing=0.05)\n",
    "\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.replace(\"origin=\", \"\"))) # fix titles\n",
    "\n",
    "for i,average in enumerate(dict(df.groupby('origin').points.mean()[df.origin.unique()]).values()):\n",
    "    fig.add_vline(x=average, line_dash=\"dot\", row=6-int(i/6), col=(1+i)%6)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# population model\n",
    "pop_parameter_mu_μ = 0\n",
    "pop_parameter_sigma_σ = 1\n",
    "normal_distribution = stats.norm(loc=pop_parameter_mu_μ, scale=pop_parameter_sigma_σ) \n",
    "\n",
    "n = 100 # adjust and experiment with this\n",
    "# np.random.seed(130)\n",
    "x = normal_distribution.rvs(size=n) # \"x\" is a sample\n",
    "\n",
    "print(\"The sample mean for the current sample is\", x.mean()) \n",
    "# sample average \"x-bar\" a (sample) \"statistic\" (not a parameter)\n",
    "print(x)\n",
    "fig = px.histogram(pd.DataFrame({'sampled values': x}), x='sampled values',\n",
    "                   histnorm='probability density') # so the scale matches the pdf below\n",
    "fig.add_vline(x=x.mean(), line_dash=\"dot\", annotation_text='Sample mean '+str(x.mean()))\n",
    "\n",
    "# pdf stands for \"probability density function\"\n",
    "support = np.linspace(-4,4,100)\n",
    "fig.add_trace(go.Scatter(x=support, y=normal_distribution.pdf(support), \n",
    "                         mode='lines', name='Poulation Model<br>(normal distribution)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_simulations = 1000 # adjust and experiment with this\n",
    "simulated_means = np.zeros(number_of_simulations)\n",
    "\n",
    "# np.random.seed(130) # ?\n",
    "n = 100 # adjust and experiment with this\n",
    "\n",
    "for i in range(number_of_simulations):\n",
    "    # np.random.seed(130) # ?\n",
    "    simulated_means[i] = stats.norm(loc=0, scale=1).rvs(size=n).mean()\n",
    "\n",
    "title = str(number_of_simulations)+' simulated means for sample of size n = '+str(n)\n",
    "fig = px.histogram(pd.DataFrame({title: simulated_means}), x=title,\n",
    "                   histnorm='probability density')    \n",
    "\n",
    "support = np.linspace(simulated_means.min(),simulated_means.max(),100)\n",
    "fig.add_trace(go.Scatter(x=support, y=stats.norm(0,scale=1/np.sqrt(n)).pdf(support), \n",
    "                         mode='lines', name='A theoretical<br>distribution of<br>\"averages\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population model\n",
    "pop_parameter_alpha_α = 2\n",
    "pop_parameter_theta_θ = 4\n",
    "gamma_distribution = stats.gamma(a=pop_parameter_alpha_α, scale=pop_parameter_theta_θ)\n",
    "\n",
    "n = 100 # adjust and experiment with this\n",
    "# np.random.seed(130)\n",
    "x = gamma_distribution.rvs(size=n) # \"x\" is a sample\n",
    "\n",
    "print(\"The sample mean for the current sample is\", x.mean()) \n",
    "# sample average \"x-bar\" a (sample) \"statistic\" (not a parameter)\n",
    "# print(x)\n",
    "\n",
    "fig = px.histogram(pd.DataFrame({'sampled values': x}), x='sampled values',\n",
    "                   histnorm='probability density') # so the scale matches the pdf below\n",
    "fig.add_vline(x=x.mean(), line_dash=\"dot\", annotation_text='Sample mean '+str(x.mean()))\n",
    "\n",
    "support = np.linspace(0,50,100)\n",
    "fig.add_trace(go.Scatter(x=support, y=gamma_distribution.pdf(support), \n",
    "                         mode='lines', name='Poulation Model<br>(gamma distribution)'))\n",
    "# pdf stands for \"probability density function\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_simulations = 1000 # adjust and experiment with this\n",
    "simulated_means = np.zeros(number_of_simulations)\n",
    "\n",
    "# np.random.seed(130) # ?\n",
    "n = 100 # adjust and experiment with this\n",
    "\n",
    "for i in range(number_of_simulations):\n",
    "    # np.random.seed(130) # ?\n",
    "    simulated_means[i] = stats.norm(loc=0, scale=1).rvs(size=n).mean()\n",
    "\n",
    "title = str(number_of_simulations)+' simulated means for sample of size n = '+str(n)\n",
    "fig = px.histogram(pd.DataFrame({title: simulated_means}), x=title,\n",
    "                   histnorm='probability density')    \n",
    "\n",
    "support = np.linspace(simulated_means.min(),simulated_means.max(),100)\n",
    "fig.add_trace(go.Scatter(x=support, y=stats.norm(0,scale=1/np.sqrt(n)).pdf(support), \n",
    "                         mode='lines', name='A theoretical<br>distribution of<br>\"averages\"'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsY7SGTsqIIv"
   },
   "source": [
    "#### Bootstrapping [20/40 minutes]: pretending a sample is the population\n",
    "\n",
    "1. Why `replace=False`?\n",
    "2. Why is `n` the same as the original sample size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = (df.origin=='Guatemala') | (df.origin=='Mexico')\n",
    "px.histogram(df[keep], x='points', facet_col='origin', facet_col_wrap=2, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contry = 'Mexico' \n",
    "\n",
    "# bootstrapping is when `replace=True` and `n` is the original sample size\n",
    "# and we do this over and over to see the behavior of sample statistics\n",
    "n_ = (df.origin==contry).sum() # ?\n",
    "replace_ = True # ?\n",
    "\n",
    "x = df[df.origin==contry].sample(n=n_, replace=replace_).points\n",
    "print(\"The sample mean for the current sample is\", x.mean()) \n",
    "# sample average \"x-bar\" a (sample) \"statistic\" (not a parameter)\n",
    "\n",
    "dat = pd.DataFrame({'values': np.r_[df[df.origin==contry].points.values,x],\n",
    "                    'sample': np.r_[['Orginal Sample']*(df.origin==contry).sum(),\n",
    "                                    ['Bootstrap Sample']*n_]})             \n",
    "\n",
    "fig = px.histogram(dat, x=\"values\", color=\"sample\", barmode=\"overlay\")\n",
    "fig.add_vline(x=x.mean(), line_dash=\"dot\", annotation_text='Sample mean '+str(x.mean()))\n",
    "fig.update_layout(yaxis_range=[0,30])\n",
    "# Notice that we don't have a \"Poulation Model\"... only the \"Original Sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_simulations = 1000 # adjust and experiment with this\n",
    "simulated_means = np.zeros(number_of_simulations)\n",
    "\n",
    "# np.random.seed(130) # ?\n",
    "n = 100 # adjust and experiment with this\n",
    "\n",
    "for i in range(number_of_simulations):\n",
    "    # np.random.seed(130) # ?\n",
    "    simulated_means[i] = df[df.origin==contry].sample(n=n_, replace=replace_).points.mean()\n",
    "\n",
    "title = str(number_of_simulations)+' simulated means for sample of size n = '+str(n)\n",
    "fig = px.histogram(pd.DataFrame({title: simulated_means}), x=title,\n",
    "                   histnorm='probability density')    \n",
    "\n",
    "support = np.linspace(simulated_means.min(),simulated_means.max(),100)\n",
    "fig.add_trace(go.Scatter(x=support, y=stats.norm(0,scale=1/np.sqrt(n)).pdf(support), \n",
    "                         mode='lines', name='A theoretical<br>distribution of<br>\"averages\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_simulations = 1000 # adjust and experiment with this\n",
    "simulated_means = np.zeros(number_of_simulations)\n",
    "\n",
    "# np.random.seed(130) # ?\n",
    "n = (df.origin==contry).sum()\n",
    "\n",
    "for i in range(number_of_simulations):\n",
    "    simulated_means[i] = stats.norm(loc=0, scale=1).rvs(size=n).mean()\n",
    "\n",
    "title = str(number_of_simulations)+' simulated means for sample of size n = '+str(n)\n",
    "fig = px.histogram(pd.DataFrame({title: simulated_means}), x=title,\n",
    "                   histnorm='probability density')    \n",
    "\n",
    "support = np.linspace(simulated_means.min(),simulated_means.max(),100)\n",
    "fig.add_trace(go.Scatter(x=support, y=stats.norm(0,scale=1/np.sqrt(n)).pdf(support), \n",
    "                         mode='lines', name='A theoretical<br>distribution of<br>\"averages\"'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wIwWNZkqCNR"
   },
   "source": [
    "### Communication [40 minutes]\n",
    "\n",
    "#### Activity 1 [20/40 minutes]\n",
    "\n",
    "Break into 5 groups of students, assigning each group to one of the questions. Groups discuss questions for 5 minutes, and then each group (in order) provides their answer to the class for 3 minutes.\n",
    "\n",
    "1. What are the differences between sampling from a \"population model\" (such as a normal or gamma distribution) compared to bootstrap sampling from an original sample? \n",
    "\n",
    "2. What happens to the variability of sample mean statistics when sampling from a \"population model\" (such as a normal or gamma distribution) as the sample size (n) increases?\n",
    "\n",
    "3. Why does it make sense to consider changing the sample size when sampling from a \"population model\" (such as a normal or gamma distribution) but it does not make sense to change the sample size when considering bootstrapped samples from an original sample? \n",
    "\n",
    "4. If you had a histogram of bootstrapped sample means representing the variability of means that an observed sample of size n produces, how would you give a range estimating what the sample mean of a future sample of size n might be? \n",
    "\n",
    "5. If you had a theoretical distribution of \"averages\" representing the variability of means that an observed sample of size n produces, how would you give a range estimating what the sample mean of a future sample of size n might be? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_hy6xCxfpg9"
   },
   "source": [
    "#### Activity 2 [20/40 minutes]\n",
    "\n",
    "Break into 3 groups of students, assigning each group to one of the questions. Groups discuss questions for 5 minutes, and then each group (in order) provides their answer to the class for 5 minutes.\n",
    "\n",
    "1. What is the process of bootstrapping?\n",
    "2. What is the main purpose of bootstrapping?\n",
    "3. If you had a hypothesis about what the average of a sample of size n from a population was, and then you observed the sample, how could you use bootstrapping as evidence in favor or against your hypothesis? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework [0 minutes]\n",
    "\n",
    "> Code and write all your answers in a python notebook (in code and markdown cells) and save your python jupyter notebook in your own account and \"repo\" on [github.com](github.com) and submit a link to that notebook though Quercus for assignment marking.\n",
    "\n",
    "#### Pre-lecture preparation / homework \n",
    "\n",
    "To prepare for this weeks lecture, first watch this video [introduction to bootstrapping](https://www.youtube.com/watch?v=Xz0x-8-cgaQ). Then interact with ChatGPT to clarify what is meant by the following concepts introduced in the video.  \n",
    "\n",
    "1. The video mentioned the \"standard error of the mean\" as being the \"standard deviation\" of the distribution bootstrapped means.  What is the difference between the \"standard error of the mean\" and the \"standard deviation\" of the original data? \n",
    "    1. Include both your answer and a log of your interactions with ChatGPT in your notebook submission for this question.\n",
    "\n",
    "2. The video suggested that the \"standard error of the mean\" could be used to create a confidence interval, but didn't describe exactly how to do this.  How can we use the \"standard error of the mean\" to create a 95% confidence interval which \"covers 95% of the bootstrapped sample means\"?\n",
    "    1. Include both your answer and a log of your interactions with ChatGPT in your notebook submission for this question.\n",
    "\n",
    "3. Creating the \"plus and minus 2 times standard error\" confidence interval addressed in the previous problem will indeed cover approximately 95% of the bootstrapped sample means. Alternatively, how do we create a 95% bootstrapped confidence interval which more exactly covers 95% of the bootstrapped sample means based on the sampled distribution (aka values) of the bootstrapped means?\n",
    "    1. Include both your answer and a log of your interactions with ChatGPT in your notebook submission for this question.\n",
    "\n",
    "4. The video mentioned that bootstrap confidence intervals could apply to other statistics of the sample, such as the \"median\". Provide code to produce a 95% bootstrap confidence interval and comment the code to demonstrate where it can be changed to produce a 95% bootstrap confidence interval for different sample statistic.\n",
    "    1. Include both your answer and a log of your interactions with ChatGPT in your notebook submission for this question.\n",
    "\n",
    "5. The video introduced hypothesis testing by saying that \"the confidence interval covers zero, so we cannot reject the hypothesis that the drug is not doing anything\".  This conclusion could referred to as \"failing to reject the null hypothesis\", where the term \"null\" refers to the concept of \"no effect\".  Why does a confidence interval overlapping zero \"fail to reject the null hypothesis\" when the observed sample mean statistic itself is not zero? \n",
    "    1. Include both your answer and a log of your interactions with ChatGPT in your notebook submission for this question.\n",
    "\n",
    "6. A formal null hypothesis has the form $H_0: \\mu=0$ which means that the average value $\\mu$ in population average is $0$. The alternative of this would be $H_A: H_0 \\text{ is false}$ which means that the average value $\\mu$ in population average is not $0$. What is the difference between the observed sample values in the sample $x_i$ (for $i = 1, \\cdots, n$), the observed sample average $\\bar x$, and the actual value of $\\mu$?\n",
    "    1. Include both your answer and a log of your interactions with ChatGPT in your notebook submission for this question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-lecture homework \n",
    "\n",
    "7. Complete the following assignment. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Vaccine Data \n",
    "\n",
    "## Overview\n",
    "\n",
    "The company AliTech has created a new vaccine that aims to improve the health of the people who take it. Your job is to use what you have learned in the course to give evidence for whether or not the vaccine is effective. \n",
    "\n",
    "## Data \n",
    "AliTech has released the following data.\n",
    "\n",
    "~~~csv\n",
    "PatientID,Age,Gender,InitialHealthScore,FinalHealthScore\n",
    "1,45,M,84,86\n",
    "2,34,F,78,86\n",
    "3,29,M,83,80\n",
    "4,52,F,81,86\n",
    "5,37,M,81,84\n",
    "6,41,F,80,86\n",
    "7,33,M,79,86\n",
    "8,48,F,85,82\n",
    "9,26,M,76,83\n",
    "10,39,F,83,84\n",
    "~~~\n",
    "\n",
    "## Deliverables\n",
    "While you can choose how to approach the project, we are interested in evaluating your report relative to the following deliverables.\n",
    "\n",
    "- A formal null hypothesis for this context.\n",
    "- A visual presentation giving some initial insight into the comparison of interest.\n",
    "- A quantitative analysis of the data and an explanation of the method and purpose of this method.\n",
    "- A conclusion regarding the null hypothesis after analyzing the data with your methodology.\n",
    "- The clarity of your documentation, code, and written report. \n",
    "\n",
    "> Consider organizing your report within the following outline template.\n",
    "> 1. Problem Introduction \n",
    ">     1. Statement of the Null Hypothesis\n",
    ">     2. Data Visualization (motivating and illustrating the comparison of interest)\n",
    "> 2. Quantitative Analysis\n",
    ">     1. Methodology Code and Explanations\n",
    ">     2. Supporting Visualizations\n",
    "> 3. Findings and Discussion\n",
    ">     1. Conclusion regarding the Null Hypothesis\n",
    ">     2. Further Considerations\n",
    "\n",
    "### Further Instructions:\n",
    "- When using random functions, you should make your analysis reproducible by using the `np.random.seed()` function\n",
    "- Create a CSV file and read that file in with your code, but do include the CSV file along with your submission\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
