{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91e206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "The null hypothesis must be based on observable and measurable data. For example, it could be an average, a proportion, or some other numerical statistic. The null hypothesis is usually stated as a \"null\" or \"no difference\" case, such as \"the means of the two groups were equal\" or \"the treatment had no effect on the outcome.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784686b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Basically, we collect a sample(xi) caculate the average sample.We then associate this estimate with a specific value to make a comparison to determine if there is enough evidence to suggest a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d9b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "When we calculate a p-value, we \"imagine a world where the null hypothesis is true\" because we are trying to determine how likely it is to observe the data we have (or something more extreme) under the assumption that the null hypothesis is correct.\n",
    "\n",
    "By assuming the null hypothesis is true, we create a reference point—a theoretical distribution called the sampling distribution of the test statistic under the null hypothesis. This distribution shows us the range of values we would expect to see if there were no actual effect or difference.\n",
    "\n",
    "The p-value is then the probability of observing a test statistic as extreme as, or more extreme than, what we have from our sample data, based on this assumed distribution. If this probability (p-value) is very low, it suggests that our observed data is unlikely under the null hypothesis, leading us to consider rejecting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099b520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A smaller p-value makes the null hypothesis look more \"ridiculous\" because it indicates that the data we observed is very unlikely to occur if the null hypothesis were actually true. Here’s how this works:\n",
    "\n",
    "When we conduct a hypothesis test, we assume that the null hypothesis is true and then look at where our observed test statistic falls within the sampling distribution (which is the distribution of all possible outcomes under the assumption that the null hypothesis is true).\n",
    "\n",
    "If the p-value is small, it means our observed test statistic is far out in the tail of this distribution—it's an extreme value. This implies that such a result would rarely happen if the null hypothesis were correct. Essentially, a small p-value suggests that the null hypothesis does not align well with the observed data, making it seem unreasonable or \"ridiculous.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff5231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "To simulate the p-value, we use a \"50/50 coin-flipping\" model to test the null hypothesis (H0), which states that humans have no preference for tilting their heads left or right when kissing. We assume that each couple has a 50% chance of tilting to the right and a 50% chance of tilting to the left. Based on the data (80 out of 124 couples tilted to the right, approximately 64.5%), we compare the observed proportion to the expected proportion under the null hypothesis (50%).\n",
    "\n",
    "Steps to Simulate the p-value:\n",
    "Set Up the Simulation:\n",
    "\n",
    "Under H0, each trial (a couple kissing) has a 50% chance of resulting in a right tilt.\n",
    "We simulate this process multiple times, for example, by flipping a virtual coin for each of the 124 couples across a large number of simulations (e.g., 10,000 times).\n",
    "Calculate the Proportion:\n",
    "\n",
    "For each simulated set of 124 couples, record the number of right tilts and calculate the proportion.\n",
    "This generates a distribution of the proportion of right tilts under the assumption that there is no preference.\n",
    "Determine the p-value:\n",
    "\n",
    "The p-value is the proportion of simulated outcomes where the number of right tilts is equal to or greater than the observed result (80 right tilts or 64.5%).\n",
    "Essentially, it's the probability of observing a result as extreme as ours (or more extreme) if the null hypothesis is true.\n",
    "Interpret the p-value:\n",
    "\n",
    "A small p-value (typically less than 0.05) would suggest that the observed result is unlikely under the null hypothesis, providing evidence against H0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bc5a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "A p-value tells us the probability of observing the data we have (or something more extreme) assuming the null hypothesis is true. A small p-value suggests that the observed data is unlikely under the null hypothesis, but it does not provide absolute proof; it only indicates that the evidence is against the null hypothesis. It implies that we might reject the null hypothesis, but there’s always a chance (however small) that the result happened by random chance.\n",
    "\n",
    "On the other hand, a large p-value means that the data is consistent with the null hypothesis, but it doesn’t definitively prove the null hypothesis is true; it only indicates that we don’t have enough evidence to reject it.\n",
    "Regarding Fido's innocence or guilt:\n",
    "\n",
    "A small p-value suggests there is evidence against his innocence, but it doesn’t prove he’s guilty.\n",
    "A large p-value suggests we don’t have enough evidence to prove his guilt, but it doesn’t prove he’s innocent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bfdf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "To adjust the code for a \"one-sided\" (or \"one-tailed\") test instead of the \"two-sided\" (or \"two-tailed\") test provided in the \"Vaccine Data Analysis Assignment,\" we'll focus on how the p-value calculation is modified. Here's a breakdown of what changes in the code, how it affects the interpretation of the hypothesis test, and whether we should expect the p-value to be smaller.\n",
    "\n",
    "Changes in the Code:\n",
    "Specify the direction of the test:\n",
    "\n",
    "In a two-sided test, we test for a difference in either direction (greater or smaller than the mean), which means the p-value considers both tails of the distribution.\n",
    "In a one-sided test, we only test for a difference in one specific direction (e.g., whether the mean is greater than or less than a specified value), so the p-value calculation focuses on just one tail of the distribution.\n",
    "Adjust the p-value calculation:\n",
    "\n",
    "In the original code (for a two-sided test), the p-value might be calculated using:\n",
    "python\n",
    "\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(test_statistic)))\n",
    "Here, we multiply by 2 because we consider both ends (tails) of the distribution.\n",
    "For a one-sided test, the code changes to:\n",
    "python\n",
    "\n",
    "p_value = 1 - stats.norm.cdf(test_statistic)\n",
    "(if we are testing for values greater than the hypothesized mean) or\n",
    "python\n",
    "\n",
    "p_value = stats.norm.cdf(test_statistic)\n",
    "(if we are testing for values less than the hypothesized mean).\n",
    "This version only considers one side of the distribution, thus reflecting a one-tailed approach.\n",
    "How This Changes the Interpretation:\n",
    "In a two-sided test, we are interested in detecting deviations in both directions. For instance, if we're testing whether a vaccine has an effect, we want to know if it either increases or decreases the response compared to the control.\n",
    "In a one-sided test, we focus on deviations in a single, specified direction. For example, we may only be interested in whether the vaccine increases the immune response. If the immune response is lower, we don’t consider it in our test.\n",
    "Should We Expect the p-value to Be Smaller in a One-Tailed Test?\n",
    "Yes, we should generally expect the p-value to be smaller in a one-tailed test compared to a two-tailed test, provided the observed effect is in the direction specified by the one-tailed test. This is because:\n",
    "\n",
    "A one-tailed test only accounts for the probability of observing the data (or more extreme data) in one direction, while a two-tailed test divides the probability into both directions, effectively doubling the area considered.\n",
    "Therefore, for the same test statistic value, the p-value in a one-tailed test is half of what it would be in a two-tailed test (assuming the effect is in the hypothesized direction).\n",
    "Example Summary:\n",
    "If the two-sided test yields a p-value of, say, 0.04, the one-sided test (assuming the effect is in the hypothesized direction) would yield a p-value of 0.02.\n",
    "However, if the effect is in the opposite direction of the one-tailed hypothesis, the p-value would be close to 1, indicating no evidence against the null hypothesis in that direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a313434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Relationship between This Experiment and the Original with Fisher and Bristol\n",
    "This experiment mirrors Fisher's tea test, but there are key differences. The sample size in Fisher’s experiment was only 8 trials, while this experiment uses a larger sample of 80 students. Additionally, the original experiment was highly personalized, focusing on Dr. Bristol’s specific taste perception. In contrast, this experiment tests a broader group of students, treating the ability to distinguish the order as a generalized skill or perception ability.\n",
    "\n",
    "Statements of the Null Hypothesis and Alternative Hypothesis\n",
    "Null Hypothesis (H0): The proportion of students who correctly identify the pouring order is 0.5 (students are guessing). Formally, H0: p = 0.5. Informally, this means \"The students are simply guessing, so they should be right about half the time.\"\n",
    "\n",
    "Alternative Hypothesis (H1): The proportion of students who correctly identify the pouring order is greater than 0.5 (students have a genuine ability to distinguish the order). Formally, H1: p > 0.5. Informally, this means \"The students have some skill or perception that allows them to correctly identify the pouring order more than half the time.\"\n",
    "\n",
    "Quantitative Analysis\n",
    "To test these hypotheses, a one-sided hypothesis test is used because we are specifically interested in whether the proportion is greater than 0.5. We calculate the test statistic based on the observed proportion of 49 out of 80. The sample size is 80, and the number of correct identifications is 49, giving a sample proportion of approximately 0.6125.\n",
    "\n",
    "Methodology Code and Explanations\n",
    "We use a z-test for proportions to perform the hypothesis test. The z-statistic is calculated using the formula\n",
    "\n",
    "The p-value is then calculated using the cumulative distribution function (CDF) for the normal distribution, assuming a normal approximation due to the large sample size.\n",
    "\n",
    "Here’s the code:\n",
    "\n",
    "python\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "n = 80\n",
    "x = 49\n",
    "p_hat = x / n\n",
    "p_0 = 0.5\n",
    "\n",
    "# Calculate the z-statistic\n",
    "z = (p_hat - p_0) / np.sqrt((p_0 * (1 - p_0)) / n)\n",
    "\n",
    "# Calculate the p-value for a one-sided test\n",
    "p_value = 1 - stats.norm.cdf(z)\n",
    "\n",
    "# Output results\n",
    "print(f\"Test Statistic (z): {z:.4f}\")\n",
    "print(f\"One-Sided p-value: {p_value:.4f}\")\n",
    "This code sets a random seed for reproducibility and calculates the z-statistic based on the observed sample proportion and the null hypothesis proportion. It then computes the p-value using the right tail of the normal distribution because we are testing if the observed proportion is greater than the hypothesized proportion.\n",
    "\n",
    "Supporting Visualizations (Optional)\n",
    "To visualize the results, we can plot the sampling distribution of the z-statistic under the null hypothesis and highlight the area corresponding to the p-value:\n",
    "\n",
    "python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the normal distribution under H0\n",
    "x_values = np.linspace(-3, 3, 1000)\n",
    "y_values = stats.norm.pdf(x_values)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_values, y_values, label='Standard Normal Distribution')\n",
    "plt.fill_between(x_values, 0, y_values, where=(x_values >= z), color='red', alpha=0.5, label='p-value region')\n",
    "plt.axvline(z, color='blue', linestyle='--', label=f'z = {z:.2f}')\n",
    "plt.title('Sampling Distribution Under H0')\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "Findings and Discussion\n",
    "If the z-statistic is significantly large (greater than a critical value, such as 1.645 for a 5% significance level), this indicates that the observed proportion is significantly higher than we would expect if students were guessing. If the p-value is less than 0.05, we reject the null hypothesis and conclude that there is evidence suggesting that students can differentiate the pouring order better than by chance.\n",
    "\n",
    "Conclusion Regarding the Null Hypothesis\n",
    "Based on the calculated p-value and test statistic:\n",
    "\n",
    "If the p-value is small (for example, less than 0.05), we have sufficient evidence to reject the null hypothesis and suggest that students indeed have the ability to determine the pouring order.\n",
    "If the p-value is large, we fail to reject the null hypothesis, meaning there is not enough evidence to conclude that students are better than random guessing.\n",
    "This approach demonstrates a structured method for performing a one-sided hypothesis test, highlighting the relationship between the observed test statistic, the sampling distribution, and the interpretation of the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9bc229",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
